{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the data according to the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_raw_data=\"1. Raw Data\"\n",
    "path_to_processed_data=\"2. Processed data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-month enrollment data (12-month unduplicated headcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_effy_list=[\"effy2015_rv.csv\",\"effy2016_rv.csv\",\"effy2017_rv.csv\",\"effy2018.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(path_to_raw_data+\"\\\\12-Month Enrollment\\\\\"+\"effy2014_rv.csv\")\n",
    "# df1.set_index('UNITID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_colums(x,year):\n",
    "#     print(x)\n",
    "    li_col=[\"UNITID\",\"EFFYLEV\",\"AWLEVEL\",\"CIPCODE\",\"AWLEVELC\",\"EFALEVEL\"]\n",
    "    if x not in li_col:\n",
    "        return str(x)+'_'+str(year)\n",
    "    else:\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_effy_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\12-Month Enrollment\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "#     print(df)\n",
    "#     dfs=pd.concat(df)\n",
    "#     df1=df1.join(df,rsuffix=\"_\"+pattern[0])\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\",\"EFFYLEV\"],right_on=[\"UNITID\",\"EFFYLEV\"])\n",
    "#     df1=pd.merge([df1, df],how=\"outer\",left_on=[\"UNITID\",\"EFFYLEV\"],right_on=[\"UNITID\",\"EFFYLEV\"])\n",
    "#     big_dataframe = pd.concat(df,join=\"UNITID\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"EFFY_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-month enrollment data (12-month instructional activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_effia_list=[\"efia2014_rv.csv\",\"efia2015_rv.csv\",\"efia2016_rv.csv\",\"efia2017_rv.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(path_to_raw_data+\"\\\\12-Month Enrollment\\\\\"+\"efia2018.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_effia_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\12-Month Enrollment\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\"],right_on=[\"UNITID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"EFIA_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissions and Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admi_list=[\"adm2015_rv.csv\",\"adm2016_rv.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Admissions and Test Scores\\\\\"+\"adm2017_rv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in admi_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Admissions and Test Scores\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\"],right_on=[\"UNITID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"Admission&testscore_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Completions (Awards/degrees conferred by program (6-digit CIP code), award level, race/ethnicity, and gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_a_list=[\"c2014_a_rv.csv\",\"c2015_a_rv.csv\",\"c2016_a_rv.csv\",\"c2017_a_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Completions\\\\\"+\"c2018_a.csv\")\n",
    "df1=df1[df1['MAJORNUM']==1]\n",
    "df1=df1.drop(['MAJORNUM'],axis=1)\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "for file in c_a_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Completions\\\\\"+file)\n",
    "    df=df[df['MAJORNUM']==1]\n",
    "    df=df.drop(['MAJORNUM'],axis=1)\n",
    "#     df=df.loc[:,~df.columns.str.startswith('X')]\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\",\"AWLEVEL\",\"CIPCODE\"],right_on=[\"UNITID\",\"AWLEVEL\",\"CIPCODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>CIPCODE</th>\n",
       "      <th>AWLEVEL</th>\n",
       "      <th>XCTOTALT_2018</th>\n",
       "      <th>CTOTALT_2018</th>\n",
       "      <th>XCTOTALM_2018</th>\n",
       "      <th>CTOTALM_2018</th>\n",
       "      <th>XCTOTALW_2018</th>\n",
       "      <th>CTOTALW_2018</th>\n",
       "      <th>XCAIANT_2018</th>\n",
       "      <th>...</th>\n",
       "      <th>XCUNKNM_2017</th>\n",
       "      <th>CUNKNM_2017</th>\n",
       "      <th>XCUNKNW_2017</th>\n",
       "      <th>CUNKNW_2017</th>\n",
       "      <th>XCNRALT_2017</th>\n",
       "      <th>CNRALT_2017</th>\n",
       "      <th>XCNRALM_2017</th>\n",
       "      <th>CNRALM_2017</th>\n",
       "      <th>XCNRALW_2017</th>\n",
       "      <th>CNRALW  _2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>1.0999</td>\n",
       "      <td>5</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100654</td>\n",
       "      <td>1.1001</td>\n",
       "      <td>5</td>\n",
       "      <td>R</td>\n",
       "      <td>9.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2.0</td>\n",
       "      <td>R</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100654</td>\n",
       "      <td>1.1001</td>\n",
       "      <td>7</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100654</td>\n",
       "      <td>1.1001</td>\n",
       "      <td>17</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100654</td>\n",
       "      <td>1.9999</td>\n",
       "      <td>5</td>\n",
       "      <td>R</td>\n",
       "      <td>6.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>...</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316998</th>\n",
       "      <td>491242</td>\n",
       "      <td>12.0402</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316999</th>\n",
       "      <td>491242</td>\n",
       "      <td>12.0407</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317000</th>\n",
       "      <td>491242</td>\n",
       "      <td>99.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317001</th>\n",
       "      <td>491297</td>\n",
       "      <td>52.1899</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317002</th>\n",
       "      <td>491297</td>\n",
       "      <td>52.1899</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317003 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UNITID  CIPCODE  AWLEVEL XCTOTALT_2018  CTOTALT_2018 XCTOTALM_2018  \\\n",
       "0       100654   1.0999        5             R           5.0             Z   \n",
       "1       100654   1.1001        5             R           9.0             R   \n",
       "2       100654   1.1001        7             R           5.0             R   \n",
       "3       100654   1.1001       17             R           1.0             R   \n",
       "4       100654   1.9999        5             R           6.0             R   \n",
       "...        ...      ...      ...           ...           ...           ...   \n",
       "316998  491242  12.0402        1           NaN           NaN           NaN   \n",
       "316999  491242  12.0407        1           NaN           NaN           NaN   \n",
       "317000  491242  99.0000        1           NaN           NaN           NaN   \n",
       "317001  491297  52.1899        1           NaN           NaN           NaN   \n",
       "317002  491297  52.1899        6           NaN           NaN           NaN   \n",
       "\n",
       "        CTOTALM_2018 XCTOTALW_2018  CTOTALW_2018 XCAIANT_2018  ...  \\\n",
       "0                0.0             R           5.0            Z  ...   \n",
       "1                2.0             R           7.0            Z  ...   \n",
       "2                1.0             R           4.0            Z  ...   \n",
       "3                1.0             Z           0.0            Z  ...   \n",
       "4                1.0             R           5.0            Z  ...   \n",
       "...              ...           ...           ...          ...  ...   \n",
       "316998           NaN           NaN           NaN          NaN  ...   \n",
       "316999           NaN           NaN           NaN          NaN  ...   \n",
       "317000           NaN           NaN           NaN          NaN  ...   \n",
       "317001           NaN           NaN           NaN          NaN  ...   \n",
       "317002           NaN           NaN           NaN          NaN  ...   \n",
       "\n",
       "        XCUNKNM_2017 CUNKNM_2017  XCUNKNW_2017 CUNKNW_2017  XCNRALT_2017  \\\n",
       "0                  Z         0.0             Z         0.0             Z   \n",
       "1                  Z         0.0             Z         0.0             Z   \n",
       "2                  Z         0.0             Z         0.0             Z   \n",
       "3                  Z         0.0             Z         0.0             R   \n",
       "4                  Z         0.0             Z         0.0             Z   \n",
       "...              ...         ...           ...         ...           ...   \n",
       "316998             R         0.0             R         0.0             R   \n",
       "316999             R         0.0             R         1.0             R   \n",
       "317000             R         0.0             R         1.0             R   \n",
       "317001             R         0.0             R         0.0             R   \n",
       "317002             R         0.0             R         0.0             R   \n",
       "\n",
       "       CNRALT_2017  XCNRALM_2017 CNRALM_2017  XCNRALW_2017 CNRALW  _2017  \n",
       "0              0.0             Z         0.0             Z           0.0  \n",
       "1              0.0             Z         0.0             Z           0.0  \n",
       "2              0.0             Z         0.0             Z           0.0  \n",
       "3              1.0             R         1.0             Z           0.0  \n",
       "4              0.0             Z         0.0             Z           0.0  \n",
       "...            ...           ...         ...           ...           ...  \n",
       "316998         0.0             R         0.0             R           0.0  \n",
       "316999         0.0             R         0.0             R           0.0  \n",
       "317000         0.0             R         0.0             R           0.0  \n",
       "317001         0.0             R         0.0             R           0.0  \n",
       "317002         0.0             R         0.0             R           0.0  \n",
       "\n",
       "[317003 rows x 303 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"completion_a_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completions (Number of students receiving awards/degrees, by award level and by gender, race/ethnicity and age categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_c_list=[\"c2014_c_rv.csv\",\"c2015_c_rv.csv\",\"c2016_c_rv.csv\",\"c2017_c_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Completions\\\\\"+\"c2018_c.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in c_c_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Completions\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\",\"AWLEVELC\"],right_on=[\"UNITID\",\"AWLEVELC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"completion_c_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall Enrollment (Race/ethnicity, gender, attendance status, and level of student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_a_list=[\"ef2013a_rv.csv\",\"ef2014a_rv.csv\",\"ef2015a_rv.csv\",\"ef2016a_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+\"ef2017a_rv.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in fe_a_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\",\"EFALEVEL\"],right_on=[\"UNITID\",\"EFALEVEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"FallEnrollment_a_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall Enrollment (Age category, gender, attendance status, and level of student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_age_colums(x,year):\n",
    "#     print(x)\n",
    "    li_col=[\"UNITID\",\"EFBAGE\",\"LSTUDY\"]\n",
    "    if x not in li_col:\n",
    "        return str(x)+'_'+str(year)\n",
    "    else:\n",
    "        return str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_b_list=[\"ef2013b_rv.csv\",\"ef2014b_rv.csv\",\"ef2015b_rv.csv\",\"ef2016b_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+\"ef2017b_rv.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_age_colums(str(x),2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in fe_b_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_age_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\",\"EFBAGE\",\"LSTUDY\"],right_on=[\"UNITID\",\"EFBAGE\",\"LSTUDY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"FallEnrollment_b_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fall Enrollment (Total entering class, retention rates, and student-to-faculty ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_d_list=[\"ef2013d_rv.csv\",\"ef2014d_rv.csv\",\"ef2015d_rv.csv\",\"ef2016d_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+\"ef2017d_rv.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in fe_d_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Fall Enrollment\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\"],right_on=[\"UNITID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"FallEnrollment_d_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Financial Aid and Net Price (Student financial aid and net price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_list=[\"sfa1415_rv.csv\",\"sfa1516_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Student Financial Aid and Net Price\\\\\"+\"sfa1617_rv.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),1617))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sf_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Student Financial Aid and Net Price\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\"],right_on=[\"UNITID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"StudentFinancialnet_sfa_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Financial Aid and Net Price (Military Servicemembers and Veteran's Benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_list=[\"sfav1415_rv.csv\",\"sfav1516_rv.csv\"]\n",
    "df1=pd.read_csv(path_to_raw_data+\"\\\\Student Financial Aid and Net Price\\\\\"+\"sfav1617_rv.csv\")\n",
    "df1.columns = df1.columns.map(lambda x: check_colums(str(x),1617))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sfm_list:\n",
    "    year=re.findall('\\d+',file)\n",
    "    print(year[0])\n",
    "    df=pd.read_csv(path_to_raw_data+\"\\\\Student Financial Aid and Net Price\\\\\"+file)\n",
    "    df.columns = df.columns.map(lambda x: check_colums(str(x),year[0]))\n",
    "    df1=df1.merge(df,how=\"outer\",left_on=[\"UNITID\"],right_on=[\"UNITID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path_to_processed_data+\"StudentFinancialnet_sfav_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
